{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b73288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847620c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status() \n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch: {url}\\nError: {e}\\n\")\n",
    "        return None\n",
    "\n",
    "def extract_links(soup, base_url):\n",
    "    page_links = []\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"].strip()\n",
    "\n",
    "        if href.startswith(\"http\"):\n",
    "            page_links.append(href)\n",
    "        elif href.startswith(\"/\"):\n",
    "            full_url = urljoin(base_url, href)\n",
    "            page_links.append(full_url)\n",
    "        elif href.endswith(\".html\"):\n",
    "            full_url = urljoin(base_url, href)\n",
    "            page_links.append(full_url)\n",
    "\n",
    "    return page_links[:32]\n",
    "\n",
    "def extract_code_chunks(url, soup):\n",
    "    code_chunks = []\n",
    "    current_section = None\n",
    "    current_subsection = None\n",
    "\n",
    "    for element in soup.find_all([\"h1\", \"h2\", \"div\"]):\n",
    "        if element.name == \"h1\":\n",
    "            current_section = element.get_text()\n",
    "            current_subsection = None\n",
    "        elif element.name == \"h2\":\n",
    "            current_subsection = element.get_text()\n",
    "        elif element.name == \"div\" and \"sourceCode\" in element.get(\"class\", []):\n",
    "            code_chunk = element.get_text()\n",
    "            if code_chunk:\n",
    "                code_chunks.append({\n",
    "                    \"url\": url,\n",
    "                    \"section\": current_section,\n",
    "                    \"subsection\": current_subsection,\n",
    "                    \"code\": code_chunk\n",
    "                })\n",
    "    \n",
    "    return code_chunks\n",
    "\n",
    "def save_code_chunks_to_file(code_chunks, filename=\"bioinformatics_workshop_gitbook.json\"):\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(code_chunks, f, indent=4)\n",
    "        print(f\"Successfully saved {len(code_chunks)} code chunks to {filename}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save data to file. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a03c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching main page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/getting-started-with-r.html\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/getting-started-with-r.html\n",
      "Extracted 14 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/using-r-installing-packages-and-importingexporting-data.html\n",
      "Extracted 57 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/basic-data-structures-in-r.html\n",
      "Extracted 154 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/text-editing-and-data-transformations.html\n",
      "Extracted 226 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/getting-biological-data-from-public-repositories.html\n",
      "Extracted 258 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/basic-statistics-in-r.html\n",
      "Extracted 325 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/regressions-and-anova-in-r.html\n",
      "Extracted 375 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/multidimensional-data-in-r.html\n",
      "Extracted 403 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/graphics-and-colors.html\n",
      "Extracted 447 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/basic-graphics.html\n",
      "Extracted 503 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/sequence-alignments.html\n",
      "Extracted 526 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/estimating-phylogenetic-trees.html\n",
      "Extracted 543 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/mining-from-a-reference-dataset.html\n",
      "Extracted 552 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/introduction-to-python.html\n",
      "Extracted 554 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-keywords-and-identifiers.html\n",
      "Extracted 557 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-statements-and-expressions.html\n",
      "Extracted 563 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-data-types.html\n",
      "Extracted 570 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-strings.html\n",
      "Extracted 578 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-operators.html\n",
      "Extracted 585 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/biopython.html\n",
      "Extracted 590 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/biopython-sequences.html\n",
      "Extracted 594 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/biopython-mulitple-sequence-alignments.html\n",
      "Extracted 596 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/biopython-genomediagram.html\n",
      "Extracted 604 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/biopython-chromosome-modeling.html\n",
      "Extracted 605 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/biopython-sequence-parsing-with-plots.html\n",
      "Extracted 610 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-web-scraping-w-beautifulsoup.html\n",
      "Extracted 618 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/python-subprocess.html\n",
      "Extracted 620 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/control-structures-loops-in-r.html\n",
      "Extracted 639 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/bioinformatics-literature.html\n",
      "Extracted 640 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/importingexporting-data-into-r.html\n",
      "Extracted 666 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/working-with-proteins.html\n",
      "Extracted 681 total code chunks so far.\n",
      "Fetching page: https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/miscellaneous.html\n",
      "Extracted 693 total code chunks so far.\n",
      "Successfully saved 693 code chunks to bioinformatics_workshop_gitbook.json.\n",
      "\n",
      "Finished! Extracted 693 code chunks from 32 pages.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_url = \"https://corytophanes.github.io/BIO_BIT_Bioinformatics_209/getting-started-with-r.html\"\n",
    "    base_url = start_url.rsplit(\"/\", 1)[0] + \"/\"\n",
    "\n",
    "    print(f\"Fetching main page: {start_url}\")\n",
    "    soup = fetch_page(start_url)\n",
    "    if not soup:\n",
    "        return \n",
    "\n",
    "    page_links = extract_links(soup, base_url)\n",
    "    code_chunks = []\n",
    "    failed_links = []\n",
    "\n",
    "    for link in page_links:\n",
    "        print(f\"Fetching page: {link}\")\n",
    "        soup = fetch_page(link)\n",
    "        if soup:\n",
    "            code_chunks.extend(extract_code_chunks(link, soup))\n",
    "            print(f\"Extracted {len(code_chunks)} total code chunks so far.\")\n",
    "        else:\n",
    "            failed_links.append(link)\n",
    "\n",
    "        time.sleep(5) \n",
    "\n",
    "    if failed_links:\n",
    "        print(\"\\nThe following links failed to load:\")\n",
    "        for failed_link in failed_links:\n",
    "            print(failed_link)\n",
    "\n",
    "    save_code_chunks_to_file(code_chunks)\n",
    "\n",
    "    print(f\"\\nFinished! Extracted {len(code_chunks)} code chunks from {len(page_links) - len(failed_links)} pages.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
